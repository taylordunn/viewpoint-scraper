name: Daily Viewpoint scraper

on:
  schedule:
    # runs every day at 2 PM UTC
    - cron: "0 14 * * *"
  push:
    branches-ignore: [] # will also run when pushed to any branch

jobs:
  scrape_for_sale:
    runs-on: ubuntu-latest
    env:
      VIEWPOINT_EMAIL: ${{ secrets.VIEWPOINT_EMAIL }}
      VIEWPOINT_PASSWORD: ${{ secrets.VIEWPOINT_EMAIL }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install Python
        uses: actions/setup-python@v4
        # see details (matrix, python-version, python-version-file, etc.)
        # https://github.com/actions/setup-python
      - name: Install poetry
        uses: abatilo/actions-poetry@v2
      - name: Setup a local virtual environment (if no poetry.toml file)
        run: |
          poetry config virtualenvs.create true --local
          poetry config virtualenvs.in-project true --local
      - uses: actions/cache@v3
        name: Define a cache for the virtual environment based on the dependencies lock file
        with:
          path: ./.venv
          key: venv-${{ hashFiles('poetry.lock') }}
      - name: Install the project dependencies
        run: poetry install

      - name: Run the scraper
        run: poetry run python viewpoint_scraper/scrape_for_sale.py

      - name: Commit changes
        run: |
          git config user.name "taylordunn"
          git config user.email "t.dunn19@gmail.com"
          git add data/for_sale/*.csv
          git commit -m "update for sale properties"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Upload screenshot if it exists
        uses: actions/upload-artifact@v4
        with:
          name: selenium-screenshot
          path: screenshot.png